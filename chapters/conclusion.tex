\chapter{Conclusion and Future Directions}
%
\label{chap:conclusion}
%
Finally, we come to the conclusion of the thesis. We present a concise overview of the contributions, followed by the limitations, future directions, and prospects of our work.

\par In this thesis, we have addressed the critical yet hitherto overlooked problem of Gallbladder Cancer (GBC) detection from Ultrasound Sonography (USG). We commence our exploration in \Cref{chap:intro} by discussing the background and motivation behind tackling the problem of automated detection of GBC. 
Following that, we set the stage by emphasizing USG as a diagnostic imaging modality, and its relevance in GBC diagnosis. We also highlighted the basics of USG and the unique challenges associated with USG in the context of GBC detection in \Cref{chap:usg}. \Cref{chap:data} delved into the data acquisition protocol and provided a comprehensive dataset description for the study.

\par In \Cref{chap:gbcnet}, we addressed the challenges related to \usg images, including sensor noise, acoustic shadows, echogenic textures, small pathology size, and variations in appearance of malignancy. To tackle these issues, we introduced \gbcnet \cite{basu2022surpassing}, a novel architecture specifically designed to address the complexities of \usg imaging. Employing a deep detection approach, \gbcnet initially identifies regions of interest to nullify the impact of noise. Subsequently, a novel specialized classification network (MS-SOP) is applied to learn rich representations of malignancy. Additionally, we introduced a smoothing-based curriculum inspired by the human visual acuity to train the classifier, aiming to alleviate texture bias originating from adjacent organs and tissues.

%we attack the problems associated with USG images due to the sensor noise and artifacts such as shadows and textures, and the viewpoint variations arising from the handheld sensor. We develop GBCNet \cite{basu2022surpassing}, a new architecture to solve the problems associated with USG imaging. We have used a deep detection approach to first identify the regions of interest to focus on from the image in order to nullify the effect of the noise. Following this, a novel specialized classification network (MS-SOP) is used for learning the rich representation of the cancers. In addition, we introduce a new Gaussian smoothing-based curriculum to train the classifier in order to mitigate the texture bias arising from the adjacent organs and tissues.

\par While \gbcnet exhibits significantly superior performance compared to expert radiologists and state-of-the-art CNN models, its dependence on bounding box annotations for training the detection component proves to be a bottleneck. The specialized nature of these annotations requires expert medical professionals. In response, \Cref{chap:limited} and \Cref{chap:wsod} address a crucial challenge in medical image computing -- efficient learning with limited supervised data. We explore two distinct avenues to overcome this challenge. Firstly, in \Cref{chap:limited}, we leverage unlabeled USG video data to acquire rich representations for the downstream GBC classification task on USG images \cite{basu2022unsupervised}. We introduce an unsupervised contrastive framework that exploits both intra-video and cross-video negatives, going beyond the conventional approach of mining only cross-video negatives as suggested in previous literature. Secondly, in \Cref{chap:wsod}, we formulate GBC detection as weakly supervised object detection using only image-level labels \cite{basu2023gall}. We enhance the DETR architecture with a multiple-instance learning framework, effectively addressing weakly supervised GBC detection and achieving competitive performance without the need for costly bounding box labels or additional video data.
%Although \gbcnet provides far superior performance as compared to the expert radiologists and the state-of-the-art CNN models, the reliance on the bounding box annotations to train the detection part of \gbcnet proves to be a bottleneck. The specialized nature of the annotations necessitates extensively trained medical professionals to annotate data. In response, we tackle in \Cref{chap:limited} a key challenge in the field of medical image computing -- learning efficiently with limited supervised data. We have explored two distinct avenues to solve the challenge. We exploited the unlabelled USG video data to learn rich representations for the downstream GBC classification task on USG images. We introduced an unsupervised contrastive framework to exploit both intra-video and cross-video negatives as opposed to mining only cross-video negatives as suggested in previous literature. In another approach, we formulated the GBC detection as a weakly supervised object detection using only image-level labels. We augmented the DETR architecture with the multiple instance learning framework towards solving the weakly supervised GBC detection, and achieved competitive performance even without costly bounding box labels or additional video data. 

\par In \Cref{chap:radformer}, we delve into another fundamental challenge -- interpretability. Interpretable decision-making in automated disease detection is crucial from a clinical standpoint. To meet this need, we introduce a novel deep neural network architecture, RadFormer, designed to learn interpretable representations for the detection of  GBC from USG images \cite{basu2023radformer}. RadFormer utilizes a local bag-of-word style feature embedding approach to generate explanations that are not only human-readable but also aligned with radiological reporting standards.

\par Finally, in \Cref{chap:focusmae}, we advocate a paradigm shift to USG video-based detection from the previously employed image-based detection approaches. The need to select the key individual frames in image-based detection is susceptible to operator bias, and single images may lack conclusive features of malignancy. Embracing video-based models offers clinical streamlining as they eliminate the need to select the pivotal frames and leverage rich spatiotemporal information for more accurate GBC detection.

\section{Limitations and Scope of the Work}
%
\subsection{Limitations}
\mypara{No Testing on Real-Time Patients}
%
A limitation of our study pertains to the absence of real-time patient testing, a critical aspect in ensuring the translational impact of our methodologies. The data used in the current study is retrospective in nature, and the practical applicability and robustness of our proposed solutions remain uncertain in real-time patients. Real-time patient testing introduces a dynamic environment with inherent complexities and variations that might not be fully captured in controlled experimental conditions. This limitation calls for future research efforts to bridge the gap between simulated models and actual clinical scenarios. %, promoting the development of more practical and reliable solutions for real-world healthcare applications.

\mypara{Single Center Study}
%
Our research relies on data obtained from a single medical center, and this exclusive focus introduces a limitation regarding the external validity and generalizability of our findings. It is noteworthy that our data collection center is a top tertiary care referral hospital in Northern India, attending both local and far-off patients from different states and localities. Due to this rich demographic variation, our single-center data contains a high degree of patient variation manifesting different sub-types of the disease. However, we acknowledge the limitations of single-center data in terms of limited variation in acquisition equipment and the number of radiologists involved. The dynamics within a single center may not fully encapsulate the broader variations present in diverse healthcare settings. 

\mypara{Not Identified Early Stage GBC}
%
Our work did not tackle the problem of identifying the early stage of the Gallbladder malignancy. Identifying the signs of early stage GBC to provide treatment alternatives is a desirable outcome for clinical setup. However, the aggressive nature of GBC makes the study difficult. 

\subsection{Scope of the Work and Generalizability}
In this work, we have addressed some of the key challenges such as the presence of acoustic shadows, bias to echogenic textures, small objects (pathology), variable appearance owing to non-regular anatomy, and limited data in detecting GBC from Ultrasound with DNN models. The techniques and methods developed in this thesis, such as focused regions-of-interest, smoothing-based curriculum, multi-scale features, second-order feature attention, and global-local features, address some of the key challenges inherent to ultrasound-based GBC detection. The lack of annotated data is tackled through self-supervised pretraining and weakly supervised detectors. The video-based classification method in \Cref{chap:focusmae} helps mitigate issues of operator bias.  Our techniques were demonstrated to solve the problem of GBC detection from ultrasound in the single center retrospective data settings. Nonetheless, the methods developed in this thesis address some of the core challenges of ultrasound-based GBC detection, such as presence of acoustic shadow, echogenic textures, variability in appearance owing to non-regular anatomy. We do not expect our methods to show catastrophic failure in case of unseen data. In fact, we have recently accessed image data of 9 patients (6 benign, 3 malignant) from another tertiary care hospital in Northern India, and were able to run the inference on this data using the RadFormer model (state-of-the-art image-based technique) trained on our original dataset. RadFormer showed 100\% sensitivity (all 3 malignant cases detected correctly) and 83.3\% specificity (5 out of 6 benign cases detected correctly). Although this is a minimal dataset, the results are indicative of the generalization capability of the techniques to unseen data. However, due to the acquisition shift owing to variation in ultrasound machines and operator variability, the outcomes derived from the current study may change with the diverse conditions encountered in multi-center healthcare environments, and result in performance drop. Consequently, caution should be exercised when extrapolating the results to a more extensive, varied population, emphasizing the need for future research encompassing multiple centers.% to enhance the reliability and generalizability of our conclusions.


\section{Future Directions}

\subsection{Translation to Clinical Settings}
%
In our commitment to advancing the translation of research into practical applications, we are actively engaged in exploring the real-world potential of the methodologies developed in this thesis. One avenue of implementation involves deploying the developed models and algorithms onto an Internet-of-Things (IoT) device. This initiative aims to assess the feasibility and performance of the models in a real-time, dynamic healthcare environment. We have shared the IoT device with PGIMER Chandigarh for testing on real-time patients and providing valuable insights into the adaptability and effectiveness of our proposed solutions in a clinical setting. Furthermore, to enhance accessibility and community-level impact, we have established a proof-of-concept web application. The application will be hosted on IIT Delhi's cloud infrastructure, providing a platform for radiologists within the community to leverage the developed models as a secondary resource for improved GBC detection. We seek to democratize access to advanced diagnostic tools, potentially transforming the landscape of GBC detection by empowering community-level radiologists with cutting-edge technology. %Through these practical implementations, we aim to bridge the gap between academic research and real-world healthcare applications, contributing to the development of more practical and reliable solutions.


\subsection{Domain Adaptation/ Generalization – Multi-Center Study}
%
It is imperative to address the domain shift in medical data arising from variations in patient demographics, scanning devices, and radiologist expertise across different hospitals. At present, our study is limited to a specific center, and addressing the challenge of domain adaptation or generalization is crucial for the broader applicability of our models. A future direction will be to focus on mitigating the impact of varying data distributions across hospitals, ensuring the robustness and effectiveness of our models in diverse healthcare settings. 
%To tackle the domain adaptation/generalization problem, we are actively working on the development of models capable of adapting to the nuances of hospitals across different geographic locations. This involves designing algorithms that can seamlessly generalize across diverse datasets, accounting for the inherent variations present in medical data from distinct sources.
In line with these aspirations, we have initiated efforts to acquire data from various hospitals across the country. The nationwide data collection initiative is aimed at creating a more diverse and representative dataset that encapsulates the heterogeneity present in medical data across different healthcare institutions. By incorporating data from multiple sources, we aim to enhance the generalizability and real-world effectiveness of our models, paving the way for more robust and widely applicable solutions in the domain of medical image analysis.

\subsection{Applicability of Foundation Models}
%
%Foundation models have recently gained huge popularity in a plethora of applications. However, its applicability in medical vision is not straight forward due to the paucity of data, and the safety critical nature of the tasks. Though there are some attempts in literature \cite{xraygpt, medsam}, the systematic study of adopting large/ foundation models for medical computer vision is largely unexplored.
Foundation models have recently witnessed immense popularity and widespread adoption across various applications, demonstrating their effectiveness in diverse domains. However, their application in medical computer vision is a complex endeavor, primarily attributed to the scarcity of data and the safety-critical nature of tasks within the healthcare domain. While some preliminary attempts have been made in the literature, such as in the cases of X-ray analysis \cite{xraygpt} and medical image segmentation \cite{medsam}, the systematic exploration and study of adopting large or foundation models for medical computer vision remain largely unexplored.

\subsection{Self-supervised Learning for USG}
%
Addressing the challenge of learning from limited supervised data, especially in the context of ultrasound (USG) imaging, remains a significant hurdle in medical image computing. In this work, we have investigated a contrastive framework utilizing temporal distance as a surrogate for a similarity measure. However, given the operator's reliance on USG, anomalies may reappear in distant frames if a radiologist re-evaluates an organ later during the same scan, leading to potential similarity conflicts. Existing works on self-supervised learning for USG primarily employ techniques like reshuffling of frames \cite{reshuff}, which, given the 2D nature of USG scans of 3D organs, might not be optimal. Exploring appropriate techniques for robust self-supervised learning from USG data presents an important avenue for future research.

\subsection{Multimodal Learning}
%
%In this work, we have explored solely the radiology images (USG) without incorporating additional clinical or radiomic information. Future research opportunities lie in harnessing diverse channels of information, potentially significantly boosting diagnostic performance.
We have exclusively explored radiology images, specifically USG, without integrating additional clinical or radiomic information. Future research endeavors present exciting opportunities to harness diverse channels of information, potentially leading to a substantial enhancement in diagnostic performance.
%The current focus on radiology images serves as a foundational step, and the inclusion of complementary data sources such as clinical information and radiomic features holds promise for a more comprehensive understanding of medical conditions. 
Integrating these additional channels of information can provide a holistic view, enabling the development of more robust and accurate diagnostic models. By leveraging the synergies among various data modalities, future research can unlock new dimensions in medical image analysis, ultimately advancing the capabilities of diagnostic tools and contributing to improved patient care.

\subsection{Discovering Hidden Features with AI}
%
%Our observations indicate that RadFormer generates neural features highly correlated with malignancy, but they do not align with the RADS features used by radiologists. Exploring and understanding the clinical nature of AI-based features and leveraging their synergy with human-used features present promising avenues for future research.
Our observations suggest that RadFormer produces neural features that exhibit a high correlation with malignancy. However, these features do not align with the Radiology Data Systems (RADS) features commonly utilized by radiologists. There is a disjunction between AI-generated features and those traditionally employed by human radiologists.

Exploring and comprehending the clinical nature of AI-generated features and, more importantly, investigating the synergies that can be harnessed between these AI-based features and those utilized by human experts present promising avenues for future research. Bridging the gap between AI-derived features and human-interpretable features can potentially lead to more clinically relevant models, fostering a collaborative and complementary relationship between AI and human expertise in medical image analysis.

\par %In conclusion, we have undertaken a comprehensive exploration of detecting GBC from USG images and videos, and made contributions to the core challenges posed by the problem. We have also identified the future directions and extension of this work with translational impact. The contributions in this thesis cover novel architectures, training methods, and new public datasets with the hope of helping to improve patient care and the bleak survival statistics for GBC. 
\section{Closing Remarks}
%
In summary, our endeavor encompassed a thorough investigation into the detection of GBC from USG images and videos, resulting in significant contributions to the fundamental challenges posed by the problem. The contributions presented in this thesis span novel architectures, innovative training methods, and the creation of new public datasets.
The identified future directions and potential extensions of this work aim to translate the contributions made by this thesis into meaningful improvements in patient care and the overall survival statistics for individuals affected by GBC. The overarching goal is to enhance the effectiveness of automated GBC detection, thereby making a positive impact on clinical practices and patient outcomes.